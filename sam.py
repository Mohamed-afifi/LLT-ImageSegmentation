# -*- coding: utf-8 -*-
"""SAM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Js9KWfrzwJQHl9sG7M1G0GA9nul8BjdR
"""

pip install 'git+https://github.com/facebookresearch/segment-anything.git'

pip install -q roboflow supervision

!wget -q 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth'

!pip install ArabicOcr
!pip install openpyxl

from google.colab import drive
drive.mount('/content/drive')

import cv2
import openpyxl
from segment_anything import SamAutomaticMaskGenerator
import torch
from segment_anything import sam_model_registry
import supervision as sv
from ArabicOcr import arabicocr
from openpyxl import Workbook
import os



batch_size = 16  # or any smaller value


def extract_AkherSaa(input_string):
    # Extract the first 8 characters of the string
    title = input_string[:9].strip()
    issue = input_string[10:13].strip()
    date = input_string[14:18].strip()
    page = input_string[19:26].strip()

    return title, issue, date, page


def extract_AlArousa(input_string):
    # Extract the first 8 characters of the string
    title = input_string[:10].strip()
    issue = input_string[11:15].strip()
    date = input_string[19:22].strip()
    page = input_string[23:30].strip()
    return title, issue, date, page

def extract_AlMusawwar(input_string):
    # Extract the first 8 characters of the string
    title = input_string[:10].strip()
    issue = input_string[11:14].strip()
    date = input_string[15:19].strip()
    page = input_string[20:27].strip()

    return title, issue, date, page

def extract_AlKawakeb(input_string):
    title = input_string[:10].strip()
    issue = input_string[11:13].strip()
    date = input_string[14:18].strip()
    page = input_string[19:26].strip()
    return title, issue, date, page


folder_path ='/content/drive/MyDrive/TestFiles/AlAroussa-142-1927'
output_folder = 'images'

file_list = [file for file in os.listdir(folder_path) if file.lower().endswith('.jpg')]
print(len(file_list))
for file in file_list:
    print(file,"\n")

# Create the output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
MODEL_TYPE = "vit_h"
sam = sam_model_registry[MODEL_TYPE](checkpoint="/content/sam_vit_h_4b8939.pth")
sam.to(device=DEVICE)
mask_generator = SamAutomaticMaskGenerator(sam)

# Create the workbook and get the active sheet

output_excel_path = output_folder+"/output.xlsx"

# Check if the workbook exists
if os.path.exists(output_excel_path):
    # Load the existing workbook
    workbook = openpyxl.load_workbook(output_excel_path)
else:
    # Create a new workbook if it doesn't exist
    workbook = openpyxl.Workbook()


sheet = workbook.active

# Save the headers for the information
sheet.cell(row=1, column=1).value = "Title"
sheet.cell(row=1, column=2).value = "Issue"
sheet.cell(row=1, column=3).value = "Date"
sheet.cell(row=1, column=4).value = "Page"
sheet.cell(row=1, column=5).value = "Arabic Text"
sheet.cell(row=1, column=6).value = "Image title"


# Save the workbook once after writing the headers
#output_excel_path = os.path.join(output_folder, "output.xlsx")
workbook.save(output_excel_path)

# Iterate through the files and process each one
for file_name in file_list:
    IMAGE_PATH = os.path.join(folder_path, file_name)
    print("File Name: ", file_name)
    title, issue, date, page = None, None, None, None

    if "Akher-Saa" in file_name:
        title, issue, date, page = extract_AkherSaa(file_name)
        print(title, issue, date, page)
    elif "Al Aroussa" in file_name:
        title, issue, date, page = extract_AlArousa(file_name)
        print(title, issue, date, page)
    elif "AlMusawwar" in file_name:
        title, issue, date, page = extract_AlMusawwar(file_name)
        print(title, issue, date, page)
    elif "AlKawakeb" in file_name:
        title, issue, date, page = extract_AlKawakeb(file_name)
        print(title, issue, date, page)

    image_bgr = cv2.imread(IMAGE_PATH)
    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
    result = mask_generator.generate(image_rgb)

    mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)
    detections = sv.Detections.from_sam(result)
    annotated_image = mask_annotator.annotate(image_bgr, detections)

    annotated_image_path = os.path.join(output_folder, f"annotated_image_{file_name}")
    cv2.imwrite(annotated_image_path, annotated_image)
    print(f"Annotated image saved at: {annotated_image_path}")

    # Get the cropped image from the result[0]['crop_box'] using image_bgr[x:x2, y:y2]
    sorted_list = sorted(result, key=lambda k: k['area'], reverse=True)

    i = 0
    for _, item in enumerate(sorted_list, start=0):
        crop_box = item['bbox']
        x, y, w, h = map(round, crop_box)
        try:
        # Extract the coordinates to slice the image
            cropped_image = image_bgr[y:y + h, x:x + w]

            crop_output_path = os.path.join(output_folder, f"cropped_region_{file_name}_row{i}.jpg")
            cv2.imwrite(crop_output_path, cropped_image)

        # Use the saved image file for OCR
            image_path = crop_output_path
            out_image = os.path.join(output_folder, f"out{i}.jpg")
            results = arabicocr.arabic_ocr(image_path, out_image)

            words = [result[1] for result in results]
            os.remove(out_image)

            if len(words) > 10:
            # If words exceed 10, delete the saved image (if exists) or skip saving
                if os.path.exists(crop_output_path):
                    os.remove(crop_output_path)
                    print(f"Image {crop_output_path} deleted because it is a text block.")
            else:
                # Add a new row for each image to the sheet
                    row_index = sheet.max_row + 1
                    # Save information to the sheet (excluding image part)
                    sheet.cell(row=row_index, column=1).value = title
                    sheet.cell(row=row_index, column=2).value = issue
                    sheet.cell(row=row_index, column=3).value = date
                    sheet.cell(row=row_index, column=4).value = page
                    # Add words to the sheet
                    sheet.cell(row=row_index, column=6).value = f"cropped_region_{file_name}_row{i}.jpg"
                    # shift the image on y-Axis down
                    shift_percentage = 0.2  # 20% shift
                    original_height = image_bgr.shape[0]
                    # Update y and h for the shift
                    y_shifted = y + int(original_height * shift_percentage)
                    h_shifted = h
                    # Ensure that the shifted values are within valid bounds
                    y_shifted = max(0, y_shifted)
                    h_shifted = min(original_height - y_shifted, h_shifted)
                    # Crop the shifted region
                    cropped_image_shifted = image_bgr[y_shifted:y_shifted + h_shifted, x:x + w]
                    # Save the cropped image with the shifted region
                    crop_output_path_shifted = os.path.join(output_folder, f"OCR_CROPPED_row{i}_shifted.jpg")


                    if cropped_image_shifted.size > 0:
                        cv2.imwrite(crop_output_path_shifted, cropped_image_shifted)
                        out_image2 = os.path.join(output_folder, f"out2{i}.jpg")
                        results2 = arabicocr.arabic_ocr(crop_output_path_shifted,out_image2)  # Only pass the path to arabic_ocr, not the image itself
                        words2 = [result2[1] for result2 in results2]
                        sheet.cell(row=row_index, column=5).value = ' '.join(words2)
                        os.remove(crop_output_path_shifted)
                        os.remove(out_image2)
                        print(f" Shifted Image: {crop_output_path_shifted} deleted after extracting the text.")
                        del result
                        del mask_annotator
                        del detections
                        del annotated_image
                        del cropped_image
                    else:
                        print(f"Skipping empty image: {crop_output_path_shifted}")
                    # DELETE THE SHIFTED IMAGE

            i += 1
            if i == 4:
                break
        except TypeError as e:
            print(f"Error: {e}. Skipping this iteration.")
            continue
# Save the workbook after processing all images

    workbook.save(output_excel_path)